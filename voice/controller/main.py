"""
Wake word –ø–æ WAV-—ç—Ç–∞–ª–æ–Ω–∞–º, –≤—Å—ë –≤ Docker.
–ú–∏–∫—Ä–æ—Ñ–æ–Ω –∏ –∫–æ–ª–æ–Ω–∫–∏ ‚Äî —á–µ—Ä–µ–∑ Pulse TCP (parec/paplay), –±–µ–∑ sounddevice/PortAudio.

–ó–∞–ø–∏—Å—å —ç—Ç–∞–ª–æ–Ω–æ–≤ –Ω–∞ —Ö–æ—Å—Ç–µ:
  pip install local-wake
  lwake record wake_ref/1.wav --duration 2
  lwake record wake_ref/2.wav --duration 2
  lwake record wake_ref/3.wav --duration 2
–ü–∞–ø–∫—É wake_ref –º–æ–Ω—Ç–∏—Ä—É–µ–º –≤ WAKE_REFERENCE_DIR.
"""
import os
import sys
import subprocess
import tempfile
import requests
import wave
import logging
import sqlite3
import time
import json
import numpy as np
from silero_vad import load_silero_vad, get_speech_timestamps
from openwebui_adapter import OpenWebUIAdapter

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —É—Ä–æ–≤–Ω—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è
LOG_LEVEL = os.environ.get("LOG_LEVEL", "INFO").upper()
logging.basicConfig(
    level=getattr(logging, LOG_LEVEL, logging.INFO),
    format="%(asctime)s [%(levelname)s] %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S",
)
log = logging.getLogger("controller")
# –£–±–∏—Ä–∞–µ–º –ø–æ—Ç–æ–∫ DEBUG –æ—Ç numba/librosa (local-wake)
for _name in ("numba", "numba.core", "numba.core.ssa", "numba.core.ir", "librosa"):
    logging.getLogger(_name).setLevel(logging.WARNING)

# –ê—É–¥–∏–æ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (–∏–∑ env —Å –¥–µ—Ñ–æ–ª—Ç–∞–º–∏)
RATE = int(os.environ.get("AUDIO_RATE", "16000"))
BUFFER_SEC = float(os.environ.get("WAKE_BUFFER_SEC", "2.0"))  # –¥–ª—è wake word
COMMAND_BUFFER_SEC = float(os.environ.get("COMMAND_BUFFER_SEC", "1.0"))  # –¥–ª—è stop/wait (–∫–æ—Ä–æ—á–µ!)
SLIDE_SEC = float(os.environ.get("WAKE_SLIDE_SEC", "0.25"))
CHUNK_VAD = int(os.environ.get("VAD_CHUNK_SIZE", "512"))
VAD_WINDOW = int(os.environ.get("VAD_WINDOW_SIZE", "8000"))  # 0.5 —Å–µ–∫ –¥–ª—è Silero VAD
SILENCE_CHUNKS = int(os.environ.get("VAD_SILENCE_CHUNKS", "30"))  # —Å–∫–æ–ª—å–∫–æ —á–∞–Ω–∫–æ–≤ —Ç–∏—à–∏–Ω—ã = –∫–æ–Ω–µ—Ü —Ñ—Ä–∞–∑—ã
MIN_RECORDING_DURATION = float(os.environ.get("MIN_RECORDING_DURATION", "0.2"))  # –º–∏–Ω –¥–ª–∏–Ω–∞ –∑–∞–ø–∏—Å–∏
GRACE_PERIOD = float(os.environ.get("RECORDING_GRACE_PERIOD", "1.5"))  # –Ω–µ —Å—á–∏—Ç–∞—Ç—å —Ç–∏—à–∏–Ω—É —Å—Ä–∞–∑—É –ø–æ—Å–ª–µ wake word

# Wake word –∏ –∫–æ–º–∞–Ω–¥—ã
ref_dir = os.environ.get("WAKE_REFERENCE_DIR", "/app/wake_ref")
wake_threshold = float(os.environ.get("WAKE_THRESHOLD", "0.1"))
stop_ref_dir = os.environ.get("STOP_REF_DIR", "/app/stop_ref")  # "—Å—Ç–æ–ø" - –≤—ã—Ö–æ–¥ –∏–∑ follow-up
wait_ref_dir = os.environ.get("WAIT_REF_DIR", "/app/wait_ref")  # "–ø–æ–¥–æ–∂–¥–∏" - –ø–∞—É–∑–∞ –≤ follow-up
command_threshold = float(os.environ.get("COMMAND_THRESHOLD", "0.15"))  # –ø–æ—Ä–æ–≥ –¥–ª—è stop/wait
pulse_server = os.environ.get("PULSE_SERVER", "")

# –ó–≤—É–∫–æ–≤—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
sounds_dir = os.environ.get("SOUNDS_DIR", "/app/sounds")
sound_start = os.path.join(sounds_dir, "start.wav")     # –ø–æ—Å–ª–µ wake word
sound_end = os.path.join(sounds_dir, "end.wav")         # –ø–æ—Å–ª–µ –∑–∞–ø–∏—Å–∏ —Ñ—Ä–∞–∑—ã
sound_exit = os.path.join(sounds_dir, "exit.wav")       # –≤—ã—Ö–æ–¥ –∏–∑ follow-up

# LLM –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
LLM_MODEL = os.environ.get("LLM_MODEL", "qwen2.5:14b-instruct-q4_K_M")
LLM_REASONING_EFFORT = os.environ.get("LLM_REASONING_EFFORT", "medium")  # low, medium, high (–¥–ª—è gpt-oss)

# –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è —Ñ–æ—Ä—Å–∏—Ä–æ–≤–∞–Ω–∏—è HIGH reasoning (–µ—Å–ª–∏ –ø–µ—Ä–≤–æ–µ —Å–ª–æ–≤–æ –≤ –∑–∞–ø—Ä–æ—Å–µ)
# –ú–æ–∂–Ω–æ –∑–∞–¥–∞—Ç—å —á–µ—Ä–µ–∑ env –∫–∞–∫ —Å–ø–∏—Å–æ–∫ —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é: "–¥—É–º–∞–π,–ø–æ–¥—É–º–∞–π,—Ä–∞–∑–º—ã—à–ª—è–π"
HIGH_REASONING_KEYWORDS = os.environ.get("HIGH_REASONING_KEYWORDS", "–¥—É–º–∞–π,–ø–æ–¥—É–º–∞–π").lower().split(",")
HIGH_REASONING_KEYWORDS = [w.strip() for w in HIGH_REASONING_KEYWORDS if w.strip()]  # —É–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã

# Follow-up mode (–ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –¥–∏–∞–ª–æ–≥–∞ –±–µ–∑ wake word)
FOLLOW_UP_ENABLED = os.environ.get("FOLLOW_UP_ENABLED", "true").lower() in ("1", "true", "yes")
FOLLOW_UP_TIMEOUT = float(os.environ.get("FOLLOW_UP_TIMEOUT", "7.0"))  # —Å–µ–∫—É–Ω–¥ –ø–æ—Å–ª–µ –æ—Ç–≤–µ—Ç–∞

USE_TEXT_PREPROCESSOR = os.environ.get("USE_TEXT_PREPROCESSOR", "true").lower() in ("1", "true", "yes")

# SYSTEM_PROMPT: LLM —Å–∞–º–∞ –≥–æ—Ç–æ–≤–∏—Ç —Ç–µ–∫—Å—Ç –¥–ª—è TTS (–ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –æ—Ç–∫–ª—é—á–µ–Ω)
SYSTEM_PROMPT = os.environ.get("SYSTEM_PROMPT", """–¢—ã —Ä—É—Å—Å–∫–∏–π –≥–æ–ª–æ—Å–æ–≤–æ–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ (1-2 –∞–±–∑–∞—Ü–∞) –∏ —Ç–æ–ª—å–∫–æ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.

–ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û:
1. –ù–∞–∑–≤–∞–Ω–∏—è –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª–µ–π –∏ –ø–µ—Å–µ–Ω –≤ JSON-–¥–µ–π—Å—Ç–≤–∏—è—Ö –ø–∏—à–∏ –¢–û–ß–ù–û –ö–ê–ö –°–õ–´–®–ê–õ (–Ω–µ —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∏—Ä—É–π!)
2. –ë–µ–∑ markdown (**, __, `), —ç–º–æ–¥–∑–∏, —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª–æ–≤
3. –ü–∏—à–∏ –∫–∞–∫ –¥–ª—è —É—Å—Ç–Ω–æ–π —Ä–µ—á–∏

–ú–£–ó–´–ö–ê:
–ö–æ–≥–¥–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–æ—Å–∏—Ç –≤–∫–ª—é—á–∏—Ç—å –º—É–∑—ã–∫—É, –≤–µ—Ä–Ω–∏ JSON –≤ —Ñ–æ—Ä–º–∞—Ç–µ:
{"action": "play_music", "artist": "–∏–º—è –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—è", "song": "–Ω–∞–∑–≤–∞–Ω–∏–µ –ø–µ—Å–Ω–∏"}

–í artist/song –ø–∏—à–∏ –Ω–∞–∑–≤–∞–Ω–∏—è –¢–û–ß–ù–û –ö–ê–ö –£–°–õ–´–®–ê–õ (–ª–∞—Ç–∏–Ω–∏—Ü–µ–π –µ—Å–ª–∏ —Ç–∞–∫ —Å–∫–∞–∑–∞–ª–∏, –∫–∏—Ä–∏–ª–ª–∏—Ü–µ–π –µ—Å–ª–∏ —Ç–∞–∫ —Å–∫–∞–∑–∞–ª–∏).

–ü—Ä–∏–º–µ—Ä—ã:
- "–≤–∫–ª—é—á–∏ –∫–∏–Ω–æ" ‚Üí {"action": "play_music", "artist": "–∫–∏–Ω–æ", "song": ""}
- "–≤–∫–ª—é—á–∏ Pink Floyd High Hopes" ‚Üí {"action": "play_music", "artist": "Pink Floyd", "song": "High Hopes"}
- "–≤–∫–ª—é—á–∏ –º—É–∑—ã–∫—É –º–∞—à–∏–Ω–∞ –≤—Ä–µ–º–µ–Ω–∏" ‚Üí {"action": "play_music", "artist": "–º–∞—à–∏–Ω–∞ –≤—Ä–µ–º–µ–Ω–∏", "song": ""}

–ï—Å–ª–∏ –Ω–µ —É–≤–µ—Ä–µ–Ω –≤ –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª–µ/–ø–µ—Å–Ω–µ - —É–≥–∞–¥–∞–π –ø–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É. –í—Å–µ–≥–¥–∞ –∑–∞–ø–æ–ª–Ω—è–π —Ö–æ—Ç—è –±—ã artist –∏–ª–∏ song.
""")

# –§—Ä–∞–∑—ã –¥–ª—è —Å–±—Ä–æ—Å–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (–Ω–æ–≤—ã–π —Ä–∞–∑–≥–æ–≤–æ—Ä)
RESET_PHRASES = [
    "–Ω–æ–≤—ã–π —Ä–∞–∑–≥–æ–≤–æ—Ä", "–∑–∞–±—É–¥—å –≤—Å—ë", "–Ω–∞—á–∞–ª–∏ —Å–Ω–∞—á–∞–ª–∞", "—Å–±—Ä–æ—Å", "–Ω–æ–≤—ã–π –¥–∏–∞–ª–æ–≥",
    "clear", "new conversation", "reset",
]

def parse_llm_action(text: str):
    """–ü–∞—Ä—Å–∏—Ç JSON action –∏–∑ –æ—Ç–≤–µ—Ç–∞ LLM."""
    try:
        # –ò—â–µ–º JSON –≤ –æ—Ç–≤–µ—Ç–µ
        start = text.find('{"action":')
        if start == -1:
            return None
        
        # –ò—â–µ–º –∑–∞–∫—Ä—ã–≤–∞—é—â—É—é —Å–∫–æ–±–∫—É
        depth = 0
        for i in range(start, len(text)):
            if text[i] == '{':
                depth += 1
            elif text[i] == '}':
                depth -= 1
                if depth == 0:
                    json_str = text[start:i+1]
                    return json.loads(json_str)
        return None
    except:
        return None

# Open WebUI –ë–î –¥–ª—è –∏—Å—Ç–æ—Ä–∏–∏ —á–∞—Ç–æ–≤
WEBUI_DB_PATH = os.environ.get("WEBUI_DB_PATH", "/app/webui_data/webui.db")
USER_ID = os.environ.get("VOICE_USER_ID", "ec3ddb7c-ea1e-4672-a94d-7c92c9eab21e")  # elestrin

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–¥–∞–ø—Ç–µ—Ä–∞ Open WebUI (–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–≥—Ä—É–∂–∞–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–π –≥–æ–ª–æ—Å–æ–≤–æ–π —á–∞—Ç)
webui_adapter = OpenWebUIAdapter(WEBUI_DB_PATH, USER_ID)
log.info("Open WebUI DB: %s, user_id=%s, chat_id=%s", WEBUI_DB_PATH, USER_ID, webui_adapter.get_current_chat_id())

if not pulse_server:
    print("–ó–∞–¥–∞–π PULSE_SERVER (–Ω–∞–ø—Ä–∏–º–µ—Ä tcp:host.docker.internal:4713)", file=sys.stderr)
    sys.exit(1)

if not os.path.isdir(ref_dir) or not [f for f in os.listdir(ref_dir) if f.endswith(".wav")]:
    print(
        f"–ü–∞–ø–∫–∞ —Å —ç—Ç–∞–ª–æ–Ω–∞–º–∏ –ø—É—Å—Ç–∞ –∏–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {ref_dir}\n"
        "–ó–∞–ø–∏—à–∏ 3‚Äì4 WAV (lwake record wake_ref/1.wav) –∏ —Å–º–æ–Ω—Ç–∏—Ä—É–π –≤ WAKE_REFERENCE_DIR.",
        file=sys.stderr,
    )
    sys.exit(1)

# –ó–∞–≥—Ä—É–∂–∞–µ–º —ç—Ç–∞–ª–æ–Ω—ã (local-wake)
from lwake.listen import load_support_set
from lwake.features import extract_embedding_features, dtw_cosine_normalized_distance

support_set = load_support_set(ref_dir, method="embedding")
if not support_set:
    log.error("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —ç—Ç–∞–ª–æ–Ω—ã –∏–∑ %s", ref_dir)
    sys.exit(1)

# –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–º–∞–Ω–¥—ã stop/wait (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
stop_set = []
wait_set = []
if os.path.isdir(stop_ref_dir) and [f for f in os.listdir(stop_ref_dir) if f.endswith(".wav")]:
    stop_set = load_support_set(stop_ref_dir, method="embedding")
    log.info("Loaded %d stop command(s) from %s", len(stop_set), stop_ref_dir)
if os.path.isdir(wait_ref_dir) and [f for f in os.listdir(wait_ref_dir) if f.endswith(".wav")]:
    wait_set = load_support_set(wait_ref_dir, method="embedding")
    log.info("Loaded %d wait command(s) from %s", len(wait_set), wait_ref_dir)

vad_model = load_silero_vad()
env = {**os.environ, "PULSE_SERVER": pulse_server}

buffer_samples = int(BUFFER_SEC * RATE)  # –¥–ª—è wake word
command_buffer_samples = int(COMMAND_BUFFER_SEC * RATE)  # –¥–ª—è stop/wait
slide_samples = int(SLIDE_SEC * RATE)
slide_bytes = slide_samples * 2  # s16le

log.info("PULSE_SERVER=%s", pulse_server)
log.info("Wake ref dir=%s, threshold=%s", ref_dir, wake_threshold)
log.info("Loaded %d reference(s): %s", len(support_set), [f for f, _ in support_set])
log.info("Buffer=%d samples (%.2fs), slide=%d samples (%.2fs)", buffer_samples, BUFFER_SEC, slide_samples, SLIDE_SEC)
log.info("Chat mode: history kept, say one of %s to reset", RESET_PHRASES[:4])
log.info("Listening for wake word (distance < %s = trigger)...", wake_threshold)


def read_from_parec_until_silence(proc=None, on_ready_callback=None, timeout=None, use_grace_period=True):
    """–ß–∏—Ç–∞–µ—Ç –∏–∑ parec –∫—É—Å–∫–∞–º–∏, –ø–æ–∫–∞ VAD –Ω–µ –∑–∞—Ñ–∏–∫—Å–∏—Ä—É–µ—Ç —Ç–∏—à–∏–Ω—É.
    –ß–∏—Ç–∞–µ–º –º–∞–ª–µ–Ω—å–∫–∏–º–∏ –ø–æ—Ä—Ü–∏—è–º–∏ (CHUNK_VAD), –Ω–æ VAD –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –±–æ–ª—å—à–µ–º –æ–∫–Ω–µ (VAD_WINDOW).
    
    Grace period: –≤ –ø–µ—Ä–≤—ã–µ GRACE_PERIOD —Å–µ–∫—É–Ω–¥ –Ω–µ —Å—á–∏—Ç–∞–µ–º —Ç–∏—à–∏–Ω—É (–¥–∞—ë–º –≤—Ä–µ–º—è –Ω–∞—á–∞—Ç—å –≥–æ–≤–æ—Ä–∏—Ç—å).
    
    –ï—Å–ª–∏ proc=None, –∑–∞–ø—É—Å–∫–∞–µ—Ç parec —Å–∞–º. –ï—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω –ø—Ä–æ—Ü–µ—Å—Å - –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –µ–≥–æ.
    on_ready_callback: –≤—ã–∑—ã–≤–∞–µ—Ç—Å—è –ø–æ—Å–ª–µ —Ç–æ–≥–æ –∫–∞–∫ parec –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–ª—Å—è (–ø—Ä–æ—á–∏—Ç–∞–Ω –ø–µ—Ä–≤—ã–π —á–∞–Ω–∫).
    timeout: –µ—Å–ª–∏ –∑–∞–¥–∞–Ω - –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Å—Ç–æ–π –º–∞—Å—Å–∏–≤ –µ—Å–ª–∏ –∑–∞ —ç—Ç–æ –≤—Ä–µ–º—è –Ω–µ –±—ã–ª–æ —Ä–µ—á–∏.
    use_grace_period: –µ—Å–ª–∏ False, grace period –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è (–¥–ª—è follow-up —Ä–µ–∂–∏–º–∞).
    """
    import select
    
    if proc is None:
        proc = subprocess.Popen(
            ["parec", "--format=s16le", "--rate=%d" % RATE, "--channels=1", "--raw"],
            stdout=subprocess.PIPE,
            env=env,
        )
    audio_chunks = []
    silence = 0
    chunk_bytes = CHUNK_VAD * 2  # 512 —Å—ç–º–ø–ª–æ–≤ –¥–ª—è —á—Ç–µ–Ω–∏—è
    vad_buffer = np.array([], dtype=np.int16)  # –ë—É—Ñ–µ—Ä –¥–ª—è VAD –æ–∫–Ω–∞
    total_samples = 0  # –°—á—ë—Ç—á–∏–∫ –∑–∞–ø–∏—Å–∞–Ω–Ω—ã—Ö —Å—ç–º–ø–ª–æ–≤
    grace_samples = int(GRACE_PERIOD * RATE)  # –°–∫–æ–ª—å–∫–æ —Å—ç–º–ø–ª–æ–≤ –≤ grace period
    ready_callback_called = False
    start_time = time.time()
    speech_detected = False  # –§–ª–∞–≥ —á—Ç–æ –±—ã–ª–∞ —Ö–æ—Ç—å –∫–∞–∫–∞—è-—Ç–æ —Ä–µ—á—å
    
    try:
        while True:
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–∞–π–º–∞—É—Ç–∞ (–¥–ª—è follow-up —Ä–µ–∂–∏–º–∞) - –ö–ê–ñ–î–´–ï 0.1 —Å–µ–∫!
            # –ï—Å–ª–∏ 7 —Å–µ–∫ –±–µ–∑ —Ä–µ—á–∏ ‚Üí —Ç–∞–π–º–∞—É—Ç
            if timeout and (time.time() - start_time) > timeout:
                if not speech_detected:
                    log.debug("Recording timeout (%.1fs) without speech", timeout)
                    return np.array([], dtype=np.int16)  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π –º–∞—Å—Å–∏–≤
                # –ï—Å–ª–∏ —Ä–µ—á—å –±—ã–ª–∞ - –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –¥–æ —Ç–∏—à–∏–Ω—ã
            
            # –ù–µ–±–ª–æ–∫–∏—Ä—É—é—â–∏–π read —Å timeout 0.1 —Å–µ–∫ (—á—Ç–æ–±—ã –ø—Ä–æ–≤–µ—Ä—è—Ç—å —Ç–∞–π–º–∞—É—Ç —á–∞—Å—Ç–æ!)
            ready, _, _ = select.select([proc.stdout], [], [], 0.1)
            if not ready:
                continue  # –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö, –∏–¥—ë–º –ø—Ä–æ–≤–µ—Ä—è—Ç—å —Ç–∞–π–º–∞—É—Ç —Å–Ω–æ–≤–∞
            
            raw = proc.stdout.read(chunk_bytes)
            if len(raw) < chunk_bytes:
                break
            arr = np.frombuffer(raw, dtype=np.int16).copy()
            audio_chunks.append(arr)
            total_samples += len(arr)
            
            # –ü–æ—Å–ª–µ –ø–µ—Ä–≤–æ–≥–æ —É—Å–ø–µ—à–Ω–æ–≥–æ —á—Ç–µ–Ω–∏—è - parec –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω, –º–æ–∂–Ω–æ –∏–≥—Ä–∞—Ç—å –∑–≤—É–∫
            if not ready_callback_called and on_ready_callback:
                on_ready_callback()
                ready_callback_called = True
            
            # –î–æ–±–∞–≤–ª—è–µ–º –≤ VAD –±—É—Ñ–µ—Ä
            vad_buffer = np.concatenate([vad_buffer, arr])
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º VAD —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–∞–∫–æ–ø–∏–ª–æ—Å—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è –æ–∫–Ω–∞
            if len(vad_buffer) >= VAD_WINDOW:
                # –ë–µ—Ä—ë–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ VAD_WINDOW —Å—ç–º–ø–ª–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
                vad_chunk = vad_buffer[-VAD_WINDOW:]
                speech = get_speech_timestamps(vad_chunk, vad_model, sampling_rate=RATE)
                
                # –û—Ç–º–µ—á–∞–µ–º –µ—Å–ª–∏ –±—ã–ª–∞ —Ä–µ—á—å
                if speech:
                    if not speech_detected:
                        log.debug("VAD: speech detected at %.2fs (first detection)", time.time() - start_time)
                    speech_detected = True
                
                # Grace period: –Ω–µ —Å—á–∏—Ç–∞–µ–º —Ç–∏—à–∏–Ω—É –≤ –Ω–∞—á–∞–ª–µ –∑–∞–ø–∏—Å–∏ (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω)
                if use_grace_period and total_samples < grace_samples:
                    silence = 0  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º —Ç–∏—à–∏–Ω—É –≤ grace period
                else:
                    # –°—á–∏—Ç–∞–µ–º —Ç–∏—à–∏–Ω—É –¢–û–õ–¨–ö–û –ï–°–õ–ò –±—ã–ª–∞ —Ä–µ—á—å (–∏–Ω–∞—á–µ —Ç–∞–π–º–∞—É—Ç —Å—Ä–∞–±–æ—Ç–∞–µ—Ç)
                    if speech_detected:
                        silence = 0 if speech else silence + 1
                        if silence > SILENCE_CHUNKS:
                            log.debug("VAD: %d chunks of silence after speech, ending recording", silence)
                            break
                
                # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ VAD_WINDOW —Å—ç–º–ø–ª–æ–≤ –≤ –±—É—Ñ–µ—Ä–µ
                if len(vad_buffer) > VAD_WINDOW * 2:
                    vad_buffer = vad_buffer[-VAD_WINDOW:]
    finally:
        proc.terminate()
        try:
            proc.wait(timeout=2)
        except subprocess.TimeoutExpired:
            proc.kill()
    out = np.concatenate(audio_chunks) if audio_chunks else np.array([], dtype=np.int16)
    log.info("Recording done: %d samples (%.2fs), speech_detected=%s", len(out), len(out) / RATE, speech_detected)
    return out


def save_wav(data: np.ndarray, path: str) -> None:
    with wave.open(path, "wb") as w:
        w.setnchannels(1)
        w.setsampwidth(2)
        w.setframerate(RATE)
        w.writeframes(data.tobytes())


def play_wav(path: str) -> None:
    """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ WAV (–¥–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö –∑–≤—É–∫–æ–≤)."""
    subprocess.run(["paplay", path], env=env, check=True)

def play_wav_interruptible(path: str) -> str:
    """
    –í–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ WAV —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è –∫–æ–º–∞–Ω–¥–∞–º–∏ stop/wait.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
    - "finished": –¥–æ–∏–≥—Ä–∞–ª–æ –¥–æ –∫–æ–Ω—Ü–∞
    - "stopped": –ø—Ä–µ—Ä–≤–∞–Ω–æ –∫–æ–º–∞–Ω–¥–æ–π stop
    - "wait": –ø—Ä–µ—Ä–≤–∞–Ω–æ –∫–æ–º–∞–Ω–¥–æ–π wait (–ø–∞—É–∑–∞)
    """
    import select
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º paplay –≤ —Ñ–æ–Ω–µ
    log.debug("Starting paplay for file: %s", path)
    proc = subprocess.Popen(["paplay", path], env=env, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
    log.debug("paplay started with PID: %s", proc.pid)
    
    # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ —Å–ª—É—à–∞–µ–º –∫–æ–º–∞–Ω–¥—ã
    parec_proc = subprocess.Popen(
        ["parec", "--format=s16le", "--rate=%d" % RATE, "--channels=1", "--raw"],
        stdout=subprocess.PIPE,
        env=env,
    )
    
    chunk_bytes = CHUNK_VAD * 2
    command_buffer = np.zeros(command_buffer_samples, dtype=np.float32)
    last_command_time = 0
    loop_count = 0  # –°—á–µ—Ç—á–∏–∫ –∏—Ç–µ—Ä–∞—Ü–∏–π –¥–ª—è –¥–µ–±–∞–≥–∞
    start_time = time.time()
    max_playback_time = 300  # 5 –º–∏–Ω—É—Ç –º–∞–∫—Å–∏–º—É–º (–∑–∞—â–∏—Ç–∞ –æ—Ç –∑–∞–≤–∏—Å–∞–Ω–∏–π)
    
    try:
        log.debug("Interruptible playback: starting parec listener loop, paplay pid=%s", proc.pid)
        while proc.poll() is None:  # –ü–æ–∫–∞ paplay —Ä–∞–±–æ—Ç–∞–µ—Ç
            loop_count += 1
            
            # –ó–∞—â–∏—Ç–∞ –æ—Ç –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ–≥–æ —Ü–∏–∫–ª–∞
            elapsed = time.time() - start_time
            if elapsed > max_playback_time:
                log.error("Playback timeout after %.1fs (max %ds), killing paplay (pid %s)", elapsed, max_playback_time, proc.pid)
                proc.kill()
                break
            
            # –î–µ–±–∞–≥ –µ—Å–ª–∏ —Å–ª–∏—à–∫–æ–º –¥–æ–ª–≥–æ
            if loop_count == 100:  # ~10 —Å–µ–∫
                poll_result = proc.poll()
                log.warning("Playback running for 10s, proc.poll()=%s, paplay pid=%s", poll_result, proc.pid)
            # –ù–µ–±–ª–æ–∫–∏—Ä—É—é—â–∏–π read —Å timeout
            ready, _, _ = select.select([parec_proc.stdout], [], [], 0.1)
            if not ready:
                if loop_count % 10 == 0:  # –ö–∞–∂–¥—É—é —Å–µ–∫—É–Ω–¥—É
                    log.debug("Playback loop: no audio data (iteration %d)", loop_count)
                continue  # –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö, –ø—Ä–æ–≤–µ—Ä—è–µ–º proc.poll() —Å–Ω–æ–≤–∞
            
            # –ß–∏—Ç–∞–µ–º –∞—É–¥–∏–æ
            raw = parec_proc.stdout.read(chunk_bytes)
            if len(raw) < chunk_bytes:
                log.warning("Parec read incomplete: got %d bytes, expected %d", len(raw), chunk_bytes)
                break
            
            if loop_count % 50 == 0:  # –ö–∞–∂–¥—ã–µ ~5 —Å–µ–∫ –ø—Ä–∏ 0.1s timeout
                log.debug("Playback loop: processing audio (iteration %d)", loop_count)
            
            arr = np.frombuffer(raw, dtype=np.int16).copy()
            float_chunk = arr.astype(np.float32) / 32768.0
            command_buffer = np.roll(command_buffer, -len(float_chunk))
            command_buffer[-len(float_chunk):] = float_chunk
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–º–∞–Ω–¥—ã (—Å cooldown 0.15s —á—Ç–æ–±—ã –∫–æ—Ä–æ—Ç–∫–∏–µ –∫–æ–º–∞–Ω–¥—ã –Ω–µ —É–ø—É—Å—Ç–∏—Ç—å)
            current_time = time.time()
            if (stop_set or wait_set) and (current_time - last_command_time > 0.15):
                try:
                    feats = extract_embedding_features(y=command_buffer, sample_rate=RATE)
                    if feats is not None:
                        # Stop
                        for filename, ref_feats in stop_set:
                            try:
                                d = dtw_cosine_normalized_distance(feats, ref_feats)
                                # –õ–æ–≥–∏—Ä—É–µ–º –µ—Å–ª–∏ –±–ª–∏–∑–∫–æ –∫ –ø–æ—Ä–æ–≥—É (–≤ –ø—Ä–µ–¥–µ–ª–∞—Ö 50% –æ—Ç –ø–æ—Ä–æ–≥–∞)
                                if d < command_threshold * 1.5:
                                    log.debug("STOP check: %s distance %.4f (threshold %.4f, match=%s)", 
                                             filename, d, command_threshold, d < command_threshold)
                                if d < command_threshold:
                                    log.info("‚úì STOP TRIGGERED: %s distance %.4f < %.4f", filename, d, command_threshold)
                                    proc.kill()
                                    parec_proc.kill()
                                    return "stopped"
                            except Exception as e:
                                log.debug("STOP check failed: %s", e)
                        # Wait
                        for filename, ref_feats in wait_set:
                            try:
                                d = dtw_cosine_normalized_distance(feats, ref_feats)
                                # –õ–æ–≥–∏—Ä—É–µ–º –µ—Å–ª–∏ –±–ª–∏–∑–∫–æ –∫ –ø–æ—Ä–æ–≥—É (–≤ –ø—Ä–µ–¥–µ–ª–∞—Ö 50% –æ—Ç –ø–æ—Ä–æ–≥–∞)
                                if d < command_threshold * 1.5:
                                    log.debug("WAIT check: %s distance %.4f (threshold %.4f, match=%s)", 
                                             filename, d, command_threshold, d < command_threshold)
                                if d < command_threshold:
                                    log.info("‚úì WAIT TRIGGERED: %s distance %.4f < %.4f", filename, d, command_threshold)
                                    proc.kill()
                                    parec_proc.kill()
                                    return "wait"
                            except Exception as e:
                                log.debug("WAIT check failed: %s", e)
                except Exception as e:
                    log.debug("Feature extraction failed: %s", e)
        
        final_poll = proc.poll()
        log.debug("Playback finished normally: proc.poll()=%s, iterations=%d, elapsed=%.1fs", 
                 final_poll, loop_count, time.time() - start_time)
        return "finished"
    finally:
        # –ß–∏—Å—Ç–∏–º –ø—Ä–æ—Ü–µ—Å—Å—ã
        try:
            proc.kill()
        except:
            pass
        try:
            parec_proc.kill()
        except:
            pass
        log.debug("Interruptible playback: cleanup complete")

def play_notification(sound_type: str) -> None:
    """–í–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ –∑–≤—É–∫–æ–≤–æ–≥–æ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è (–µ—Å–ª–∏ —Ñ–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç)."""
    sound_map = {
        "start": sound_start,
        "end": sound_end,
        "exit": sound_exit,
    }
    sound_path = sound_map.get(sound_type)
    if sound_path and os.path.exists(sound_path):
        try:
            # –ò–≥—Ä–∞–µ–º –≤ —Ñ–æ–Ω–µ, –Ω–µ –±–ª–æ–∫–∏—Ä—É–µ–º
            log.info("üîä Playing sound: %s (%s)", sound_type, sound_path)
            proc = subprocess.Popen(["paplay", sound_path], env=env, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
            log.debug("play_notification(%s): paplay started, pid=%s", sound_type, proc.pid)
        except Exception as e:
            log.error("play_notification(%s): failed: %s", sound_type, e)
    else:
        log.debug("play_notification(%s): sound file not found: %s", sound_type, sound_path)

def stop_audio_playback() -> None:
    """–û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –≤—Å–µ –∑–∞–ø—É—â–µ–Ω–Ω—ã–µ paplay –ø—Ä–æ—Ü–µ—Å—Å—ã."""
    try:
        subprocess.run(["pkill", "-9", "paplay"], check=False)
        log.info("Stopped audio playback (killed paplay)")
    except:
        pass


def is_reset_phrase(text: str) -> bool:
    """–°–±—Ä–æ—Å —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –≤—Å—è —Ñ—Ä–∞–∑–∞ ‚Äî –æ–¥–Ω–∞ –∏–∑ –∫–æ–º–∞–Ω–¥ —Å–±—Ä–æ—Å–∞ (–±–µ–∑ –ª–∏—à–Ω–∏—Ö —Å–ª–æ–≤)."""
    t = text.lower().strip().rstrip(".,!?")
    return t in RESET_PHRASES


def get_adaptive_reasoning(text: str) -> str:
    """
    –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å reasoning –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–ª–æ–≤.
    
    –ü—Ä–∞–≤–∏–ª–∞:
    - –ü–µ—Ä–≤–æ–µ —Å–ª–æ–≤–æ "–¥—É–º–∞–π"/"–ø–æ–¥—É–º–∞–π" (–∏–ª–∏ –∏–∑ HIGH_REASONING_KEYWORDS) ‚Üí HIGH (–Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç –¥–ª–∏–Ω—ã)
    - <= 5 —Å–ª–æ–≤ ‚Üí LOW
    - 5 < —Å–ª–æ–≤ < 15 ‚Üí MEDIUM
    - >= 15 —Å–ª–æ–≤ ‚Üí HIGH
    """
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤–æ–µ —Å–ª–æ–≤–æ –Ω–∞ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è HIGH reasoning
    words = text.split()
    if words:
        first_word = words[0].lower().rstrip(".,!?:;")  # —É–±–∏—Ä–∞–µ–º –∑–Ω–∞–∫–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è
        if first_word in HIGH_REASONING_KEYWORDS:
            log.info("Adaptive reasoning: keyword '%s' detected ‚Üí HIGH (forced)", first_word)
            return "high"
    
    # –ü–æ–¥—Å—á—ë—Ç —Å–ª–æ–≤
    word_count = len(words)
    
    if word_count <= 5:
        log.debug("Adaptive reasoning: %d words ‚Üí LOW", word_count)
        return "low"
    elif word_count < 15:
        log.debug("Adaptive reasoning: %d words ‚Üí MEDIUM", word_count)
        return "medium"
    else:
        log.debug("Adaptive reasoning: %d words ‚Üí HIGH", word_count)
        return "high"


def get_chat_history():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—é —Ç–µ–∫—É—â–µ–≥–æ —á–∞—Ç–∞."""
    return webui_adapter.get_history()


def on_wake_detected(skip_wake_detection=False, follow_up_timeout=None):
    """
    –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–º–∞–Ω–¥—ã –ø–æ—Å–ª–µ wake word –∏–ª–∏ –≤ follow-up —Ä–µ–∂–∏–º–µ.
    skip_wake_detection=True –æ–∑–Ω–∞—á–∞–µ—Ç —á—Ç–æ –º—ã –≤ follow-up, wake word —É–∂–µ –±—ã–ª.
    follow_up_timeout: —Ç–∞–π–º–∞—É—Ç –¥–ª—è follow-up —Ä–µ–∂–∏–º–∞ (–µ—Å–ª–∏ –Ω–µ—Ç —Ä–µ—á–∏ - –≤–µ—Ä–Ω—ë—Ç "timeout").
    """
    if not skip_wake_detection:
        log.info("Wake word DETECTED ‚Äî starting command recording")
        
        # –°–†–ê–ó–£ –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –º—É–∑—ã–∫—É (–µ—Å–ª–∏ –∏–≥—Ä–∞–µ—Ç)
        try:
            requests.post("http://music:5003/stop", timeout=1)
            log.debug("Music stopped for new wake word")
        except:
            pass
        
        # –ö–æ–ª–±—ç–∫: –∏–≥—Ä–∞–µ–º –∑–≤—É–∫ –¢–û–õ–¨–ö–û –ø–æ—Å–ª–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ parec
        audio = read_from_parec_until_silence(on_ready_callback=lambda: play_notification("start"))
    else:
        log.info("Follow-up mode ‚Äî waiting for speech (timeout %.1fs)", follow_up_timeout or 0)
        # –í follow-up —Ä–µ–∂–∏–º–µ —Å —Ç–∞–π–º–∞—É—Ç–æ–º: –ø–∏–ª–∏–∫ –ø–æ—Å–ª–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏
        # –ë–ï–ó grace period! (–∏–Ω–∞—á–µ VAD –¥–µ—Ç–µ–∫—Ç–∏—Ä—É–µ—Ç —ç—Ö–æ/—à—É–º –∏ –∂–¥—ë—Ç 4.26 —Å–µ–∫ –≤–º–µ—Å—Ç–æ —Ç–∞–π–º–∞—É—Ç–∞)
        audio = read_from_parec_until_silence(
            on_ready_callback=lambda: play_notification("start"),
            timeout=follow_up_timeout,
            use_grace_period=False
        )
    
    if audio.size == 0:
        if follow_up_timeout:
            log.info("Follow-up timeout - no speech detected")
            return "timeout"
        else:
            log.warning("No audio recorded, skipping")
            return "empty"
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π –¥–ª–∏–Ω—ã (—Ñ–∏–ª—å—Ç—Ä –ª–æ–∂–Ω—ã—Ö —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π)
    duration = len(audio) / RATE
    if duration < MIN_RECORDING_DURATION:
        log.warning("Recording too short (%.2fs < %.2fs), probably false wake or cut off too early, skipping", 
                    duration, MIN_RECORDING_DURATION)
        return "empty"
    
    wav_path = tempfile.mktemp(suffix=".wav")
    reply_path = tempfile.mktemp(suffix=".wav")
    try:
        save_wav(audio, wav_path)
        play_notification("end")  # –ó–≤—É–∫ "–∑–∞–ø–∏—Å–∞–ª–∏, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º"
        log.info("STT: sending %d bytes to http://stt:5000/stt", os.path.getsize(wav_path))
        with open(wav_path, "rb") as f:
            r = requests.post("http://stt:5000/stt", files={"audio": f}, timeout=30)
        r.raise_for_status()
        text = r.json().get("text", "").strip()
        log.info("STT (user): %r", text or "(empty)")

        if not text:
            log.warning("Empty text from STT, skipping LLM/TTS")
            return "empty"
        

        # –°–±—Ä–æ—Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø–æ —Ñ—Ä–∞–∑–µ: —Å–æ–∑–¥–∞—ë–º –Ω–æ–≤—É—é —Å–µ—Å—Å–∏—é
        if is_reset_phrase(text):
            old_count = webui_adapter.get_message_count()
            webui_adapter.create_new_chat()
            log.info("Chat reset: old chat had %d msgs, new chat_id=%s", old_count, webui_adapter.get_current_chat_id())
            resp = "–û–∫–µ–π, –Ω–æ–≤—ã–π —Ä–∞–∑–≥–æ–≤–æ—Ä."
        else:
            # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–ø–ª–∏–∫—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ –ë–î
            webui_adapter.add_message("user", text)
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –∏–∑ –ë–î –∏ —à–ª—ë–º –≤ /api/chat
            history = get_chat_history()
            messages = []
            if SYSTEM_PROMPT.strip():
                messages.append({"role": "system", "content": SYSTEM_PROMPT.strip()})
            messages.extend(history)
            log.info("LLM chat: %d history msgs + system, sending to http://llm:11434/api/chat", len(history))
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º payload –¥–ª—è API –∑–∞–ø—Ä–æ—Å–∞
            payload = {"model": LLM_MODEL, "messages": messages, "stream": False}
            # –î–ª—è gpt-oss –º–æ–¥–µ–ª–µ–π –¥–æ–±–∞–≤–ª—è–µ–º reasoning effort
            if "gpt-oss" in LLM_MODEL.lower():
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π reasoning –≤–º–µ—Å—Ç–æ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ
                reasoning_level = get_adaptive_reasoning(text)
                payload["think"] = reasoning_level
                log.info("GPT-OSS adaptive reasoning: %s (text: %d words)", reasoning_level, len(text.split()))
            
            r = requests.post(
                "http://llm:11434/api/chat",
                json=payload,
                timeout=300,  # 5 –º–∏–Ω—É—Ç: –ø–µ—Ä–≤–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å 1-2 –º–∏–Ω
            )
            r.raise_for_status()
            
            # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç –∏ reasoning (–µ—Å–ª–∏ –µ—Å—Ç—å)
            message = r.json().get("message") or {}
            resp = message.get("content", "")
            thinking = message.get("thinking", "")
            if thinking:
                log.debug("LLM reasoning trace (%d chars): %s...", len(thinking), thinking[:100])
            log.info("LLM (assistant): %d chars", len(resp))
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ action (–Ω–∞–ø—Ä–∏–º–µ—Ä play_music) - –ù–ï –ó–ê–ü–£–°–ö–ê–ï–ú –º—É–∑—ã–∫—É —Å—Ä–∞–∑—É!
            # –°–Ω–∞—á–∞–ª–∞ –∏—â–µ–º —á—Ç–æ –≤–∫–ª—é—á–∏—Ç—å –∏ —Ñ–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç, –Ω–æ –º—É–∑—ã–∫—É –∑–∞–ø—É—Å—Ç–∏–º –ü–û–°–õ–ï TTS
            music_action = None
            action = parse_llm_action(resp)
            if action and action.get("action") == "play_music":
                log.info("Music action detected: %s", action)
                music_action = action  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –ü–û–°–õ–ï TTS
                try:
                    # –ò—â–µ–º —Ç—Ä–µ–∫ –ù–û –ù–ï –ó–ê–ü–£–°–ö–ê–ï–ú (—Ç–æ–ª—å–∫–æ –¥–ª—è —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –æ—Ç–≤–µ—Ç–∞)
                    music_r = requests.post(
                        "http://music:5003/search",
                        json={"artist": action.get("artist", ""), "song": action.get("song", "")},
                        timeout=15
                    )
                    if music_r.status_code == 200:
                        music_data = music_r.json()
                        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è –∏–∑ VK (–∫–∞–∫ –æ–Ω–∏ —Ç–∞–º —Ö—Ä–∞–Ω—è—Ç—Å—è)
                        resp = f"–í–∫–ª—é—á–∞—é {music_data.get('artist', '')} {music_data.get('title', '')}"
                        log.info("Music found (will play after TTS): %s", resp)
                    else:
                        resp = "–ù–µ –º–æ–≥—É –Ω–∞–π—Ç–∏ —ç—Ç—É –ø–µ—Å–Ω—é"
                        music_action = None  # –û—Ç–º–µ–Ω—è–µ–º –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ
                        log.warning("Music search failed: %s", music_r.text)
                except Exception as e:
                    log.exception("Music service unavailable: %s", e)
                    resp = "–ú—É–∑—ã–∫–∞–ª—å–Ω—ã–π —Å–µ—Ä–≤–∏—Å –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"
                    music_action = None

        if not resp:
            log.warning("Empty LLM response, skipping TTS")
            return "empty"

        # –ü—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ —Ç–µ–∫—Å—Ç–∞ –ø–µ—Ä–µ–¥ TTS (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        # –í–ê–ñ–ù–û: —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç (–ø–æ—Å–ª–µ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞) —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ë–î –¥–ª—è –¥–µ–±–∞–≥–∞
        tts_text = resp
        if USE_TEXT_PREPROCESSOR:
            log.info("Text Preprocessor: sending %d chars to http://text_preprocessor:5000/preprocess", len(resp))
            try:
                r = requests.post(
                    "http://text_preprocessor:5000/preprocess",
                    json={"text": resp, "add_ssml": True},
                    timeout=60
                )
                r.raise_for_status()
                tts_text = r.json().get("processed_text", resp)
                log.info("Text Preprocessor: processed %d ‚Üí %d chars", len(resp), len(tts_text))
            except Exception as e:
                log.warning("Text Preprocessor failed: %s, using original text", e)
                tts_text = resp
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ë–î —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç (–∫–æ—Ç–æ—Ä—ã–π —Ä–µ–∞–ª—å–Ω–æ –∏–¥–µ—Ç –≤ TTS)
        webui_adapter.add_message("assistant", tts_text)
        total_msgs = webui_adapter.get_message_count()
        log.info("Saved to DB: %d chars, total %d msgs in chat", len(tts_text), total_msgs)

        log.info("TTS: sending %d chars to http://tts:5000/tts", len(tts_text))
        # TTS —Å–∏–Ω—Ç–µ–∑ –∑–∞–Ω–∏–º–∞–µ—Ç ~1 —Å–µ–∫ –Ω–∞ 10 —Å–∏–º–≤–æ–ª–æ–≤, +–∑–∞–ø–∞—Å. –î–ª—è 1000 —Å–∏–º–≤–æ–ª–æ–≤ = 100+ —Å–µ–∫
        tts_timeout = max(120, len(tts_text) // 5)  # –º–∏–Ω–∏–º—É–º 2 –º–∏–Ω, –∏–ª–∏ 1 —Å–µ–∫ –Ω–∞ 5 —Å–∏–º–≤–æ–ª–æ–≤
        r = requests.post("http://tts:5000/tts", json={"text": tts_text}, timeout=tts_timeout)
        r.raise_for_status()
        with open(reply_path, "wb") as f:
            f.write(r.content)
        log.info("TTS: %d bytes, playing (interruptible)", len(r.content))
        playback_result = play_wav_interruptible(reply_path)
        
        # –ü–û–°–õ–ï –ø—Ä–æ–∏–≥—Ä—ã–≤–∞–Ω–∏—è –æ—Ç–≤–µ—Ç–∞ –∑–∞–ø—É—Å–∫–∞–µ–º –º—É–∑—ã–∫—É (–µ—Å–ª–∏ –±—ã–ª–∞ –∫–æ–º–∞–Ω–¥–∞ play_music)
        music_started = False
        if music_action and playback_result == "finished":
            log.info("Starting music playback after TTS finished")
            try:
                # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â—É—é –º—É–∑—ã–∫—É (–µ—Å–ª–∏ –∏–≥—Ä–∞–µ—Ç)
                try:
                    requests.post("http://music:5003/stop", timeout=2)
                except:
                    pass
                
                music_r = requests.post(
                    "http://music:5003/play",
                    json={"artist": music_action.get("artist", ""), "song": music_action.get("song", "")},
                    timeout=15
                )
                if music_r.status_code == 200:
                    log.info("Music started successfully")
                    music_started = True
                else:
                    log.warning("Music playback failed: %s", music_r.text)
            except Exception as e:
                log.exception("Failed to start music: %s", e)
        
        if playback_result == "stopped":
            log.info("Playback stopped by user")
            return "stopped"
        elif playback_result == "wait":
            log.info("Playback paused by user")
            return "success"  # –ü–∞—É–∑–∞ = –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –≤ follow-up
        elif music_started:
            log.info("Music playing - skipping follow-up")
            return "music_playing"  # –ú—É–∑—ã–∫–∞ –∏–≥—Ä–∞–µ—Ç - –ù–ï –≤—Ö–æ–¥–∏–º –≤ follow-up
        else:
            log.info("Playback finished")
            return "success"  # –£—Å–ø–µ—à–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ ‚Äî –≤—Ö–æ–¥–∏–º –≤ follow-up
    except requests.exceptions.RequestException as e:
        log.exception("API error: %s", e)
        return "error"
    except Exception as e:
        log.exception("Error: %s", e)
        return "error"
    finally:
        for p in (wav_path, reply_path):
            if os.path.exists(p):
                os.unlink(p)
def main():
    listen_cycle = 0
    while True:
        listen_cycle += 1
        log.info("Listen cycle %d: starting parec (wake word stream)", listen_cycle)
        proc = subprocess.Popen(
            ["parec", "--format=s16le", "--rate=%d" % RATE, "--channels=1", "--raw"],
            stdout=subprocess.PIPE,
            env=env,
        )
        audio_buffer = np.zeros(buffer_samples, dtype=np.float32)
        slide_count = 0

        try:
            while True:
                raw = proc.stdout.read(slide_bytes)
                if len(raw) < slide_bytes:
                    log.warning("Listen: short read %d < %d, restarting parec", len(raw), slide_bytes)
                    break
                slide_count += 1
                chunk = np.frombuffer(raw, dtype=np.int16)
                float_chunk = chunk.astype(np.float32) / 32768.0
                audio_buffer = np.roll(audio_buffer, -len(float_chunk))
                audio_buffer[-len(float_chunk) :] = float_chunk

                try:
                    feats = extract_embedding_features(y=audio_buffer, sample_rate=RATE)
                except Exception:
                    continue
                if feats is None:
                    continue

                for filename, ref_feats in support_set:
                    try:
                        d = dtw_cosine_normalized_distance(feats, ref_feats)
                        if d < wake_threshold:
                            log.info("Wake: %s distance %.4f < %.4f", filename, d, wake_threshold)
                            proc.terminate()
                            try:
                                proc.wait(timeout=2)
                            except subprocess.TimeoutExpired:
                                proc.kill()
                            
                            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–º–∞–Ω–¥—ã
                            result = on_wake_detected(skip_wake_detection=False)
                            
                            # Follow-up mode –ø–æ—Å–ª–µ –æ—Ç–≤–µ—Ç–∞ (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –±—ã–ª —É—Å–ø–µ—à–Ω—ã–π –æ—Ç–≤–µ—Ç –∏–ª–∏ stopped)
                            # –ï—Å–ª–∏ –∑–∞–ø—É—Å—Ç–∏–ª–∞—Å—å –º—É–∑—ã–∫–∞ (music_playing) - –ù–ï –≤—Ö–æ–¥–∏–º –≤ follow-up
                            if result == "music_playing":
                                log.info("Music playing - returning to wake word mode without follow-up")
                                # –ë–µ–∑ –∑–≤—É–∫–æ–≤ - –º—É–∑—ã–∫–∞ —É–∂–µ –∏–≥—Ä–∞–µ—Ç
                            elif FOLLOW_UP_ENABLED and result in ("success", "stopped"):
                                while True:
                                    # –°—Ä–∞–∑—É –∑–∞–ø—É—Å–∫–∞–µ–º –∑–∞–ø–∏—Å—å —Å —Ç–∞–π–º–∞—É—Ç–æ–º (–ø–∏–ª–∏–∫ —Å—ã–≥—Ä–∞–µ—Ç –ø–æ—Å–ª–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ parec)
                                    result2 = on_wake_detected(skip_wake_detection=True, follow_up_timeout=FOLLOW_UP_TIMEOUT)
                                    
                                    if result2 == "success":
                                        # –£—Å–ø–µ—à–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º follow-up
                                        continue
                                    
                                    elif result2 == "music_playing":
                                        # –ú—É–∑—ã–∫–∞ –∏–≥—Ä–∞–µ—Ç - –≤—ã—Ö–æ–¥ –ë–ï–ó –∑–≤—É–∫–æ–≤
                                        log.info("Music playing - exiting follow-up without sound")
                                        break
                                    
                                    elif result2 == "timeout":
                                        # –¢–∞–π–º–∞—É—Ç - –≤—ã—Ö–æ–¥ –∏–∑ follow-up
                                        log.info("Follow-up timeout ‚Üí returning to wake word mode")
                                        play_notification("exit")
                                        break
                                    
                                    else:
                                        # –î—Ä—É–≥–∏–µ —Å–ª—É—á–∞–∏ (empty, error) - –≤—ã—Ö–æ–¥
                                        log.info("Follow-up ended: %s", result2)
                                        play_notification("exit")
                                        break
                            
                            break
                    except Exception:
                        continue
                else:
                    continue
                break
        except KeyboardInterrupt:
            log.info("Stopping...")
            break
        finally:
            try:
                proc.terminate()
                proc.wait(timeout=2)
            except (subprocess.TimeoutExpired, OSError):
                proc.kill()


if __name__ == "__main__":
    main()
